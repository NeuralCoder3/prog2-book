<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h4 class="heading"><span class="type">Paragraph</span></h4>
<div class="para logical">
<div class="para">The first step in syntax analysis is <dfn class="terminology">lexing</dfn>. The name lexer comes from the greek word lexis which means “word”. The job of the lexer is to form “words” from the sequence of input characters. These words are called <dfn class="terminology">tokens</dfn>. Hence, the <dfn class="terminology">lexer</dfn> translates the stream of input characters that constitute the program text into a stream of <dfn class="terminology">tokens</dfn> which represent the “words” of the program. Each token consists of</div>
<ol class="decimal">
<li><div class="para">a lexical category (“identifier”, “addition sign”, “open parentheses”, etc.).</div></li>
<li><div class="para">the original text (if not apparent from the category)</div></li>
<li><div class="para">the source code coordinates (file, line, column) for error reports.</div></li>
</ol>
<div class="para">All other things (mostly whitespace and comments) are discarded by the lexer because they are not relevant for the syntactic correctness of the program. <a href="" class="xref" data-knowl="./knowl/fig-comp-tokens.html" title="Figure 9.1.1">Figure 9.1.1</a> shows an example program with its corresponding token stream.</div>
</div>
<span class="incontext"><a href="sec-comp-synana.html#p-1047" class="internal">in-context</a></span>
</body>
</html>
