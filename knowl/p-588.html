<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h4 class="heading"><span class="type">Paragraph</span></h4>
<div class="para">We have also omitted a solid formal derivation of worst-case run time bounds because this is in general not possible without making further assumptions. One very prominent formal approach is <em class="emphasis">universal hashing</em> where one draws <em class="emphasis">hash functions</em> randomly and is able to prove run time bounds for specific hash functions independent of the data.</div>
<span class="incontext"><a href="sec-ds-hash.html#p-588" class="internal">in-context</a></span>
</body>
</html>
